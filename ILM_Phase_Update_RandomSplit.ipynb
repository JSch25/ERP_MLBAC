{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25688f8-ca11-4223-89d8-f7c5b8b4e1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037b0977-96b0-43eb-b2c1-8a2f1c5dd594",
   "metadata": {},
   "source": [
    "Replace the placeholder with the correct filename. The data is available as a CSV file in the properly preprocessed format. The dataset consists of the attributes 'USER' and 'TCODE' (transaction permission), along with the respective labels for UPA_I, UPA_T, and UPA_R. In addition, the six user attributes ('COMPANY', 'CLASS', 'KOSTL', 'USTYP', 'DEPARTMENT', 'FUNCTION') and the permission attribute 'SUBCOMPONENT' are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf2211f-e1b3-4fa5-9d60-bad4151947f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlbac_data = pd.read_csv('mlbac_data.csv',low_memory=False).sample(frac=1, random_state=42).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de0a02-8e4c-4bda-8f28-0a69fdc51d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_all_attributes = ['USER','TCODE','COMPANY', 'CLASS', 'KOSTL', 'USTYP', 'DEPARTMENT', 'FUNCTION', 'SUBCOMPONENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299ea688-9f7f-40ad-ad6e-28e08b7d9eca",
   "metadata": {},
   "source": [
    "## RandomSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29385c31-66c2-4e12-9eaa-5eb6668a49d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split_data(X_train, X_val, X_test, y_train, y_val, y_test, y_test_pred, y_test_pred_proba, tn, fp, fn, tp, dataset_name, run):\n",
    "    train_data = X_train.copy()\n",
    "    train_data['True_Target'] = y_train\n",
    "    train_data['Predicted_Target'] = None  \n",
    "    train_data['Split'] = 'Train'\n",
    "    \n",
    "    val_data = X_val.copy()\n",
    "    val_data['True_Target'] = y_val\n",
    "    val_data['Predicted_Target'] = None  \n",
    "    val_data['Split'] = 'Validation'\n",
    "    \n",
    "    test_data = X_test.copy()\n",
    "    test_data['True_Target'] = y_test\n",
    "    test_data['Predicted_Target'] = y_test_pred\n",
    "    test_data['Split'] = 'Test'\n",
    "    \n",
    "    combined_data = pd.concat([train_data, val_data, test_data], axis=0, ignore_index=True)\n",
    "    \n",
    "    file_name = f'{dataset_name}_run_{run+1}_Randomsplit.csv'\n",
    "    \n",
    "    combined_data.to_csv(file_name, index=False)\n",
    "    print(f'Dataset saved as {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e6c16-b2d5-4be2-a60c-5a1fe2fa3aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(num_runs, train_size, test_size):\n",
    "    results = [] \n",
    "\n",
    "    for run in range(num_runs):\n",
    "        random_state = run * 10 \n",
    "        print(f\"\\nRun: {run + 1} | Random State: {random_state}\")\n",
    "\n",
    "        UPA_I = mlbac_data.drop('Target_UPA_T', axis=1).rename(columns={'Target_UPA_I': 'Target'})\n",
    "        UPA_T = mlbac_data.loc[(mlbac_data[\"Target_UPA_T\"]==1)|(mlbac_data[\"Target_UPA_T\"]==0)].drop('Target_UPA_I', axis=1).rename(columns={'Target_UPA_T': 'Target'})\n",
    "        UPA_R = mlbac_data.drop('Target_UPA_I', axis=1).rename(columns={'Target_UPA_T': 'Target'}).replace(2,0, regex=True)\n",
    "\n",
    "        UPA_I_target = UPA_I\n",
    "        UPA_I = UPA_I.drop(\"Target\", axis=1)\n",
    "        UPA_T_target = UPA_T\n",
    "        UPA_T = UPA_T.drop(\"Target\", axis=1)\n",
    "        UPA_R_target = UPA_R\n",
    "        UPA_R = UPA_R.drop(\"Target\", axis=1)\n",
    "\n",
    "        intersection_df_1 = pd.merge(pd.merge(UPA_I[['USER','TCODE']], UPA_T[['USER','TCODE']], on=['USER','TCODE']), UPA_R, on=['USER','TCODE'])\n",
    "        train_1, temp_1 = train_test_split(intersection_df_1, test_size=1-train_size, random_state=random_state)\n",
    "        val_1, test_1 = train_test_split(temp_1, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        UPA_I_remaining = UPA_I.merge(intersection_df_1[[\"USER\",\"TCODE\"]], on=['USER', 'TCODE'], how='left', indicator=True)\n",
    "        UPA_I_remaining = UPA_I_remaining[UPA_I_remaining['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        \n",
    "        UPA_T_remaining = UPA_T.merge(intersection_df_1[[\"USER\",\"TCODE\"]], on=['USER', 'TCODE'], how='left', indicator=True)\n",
    "        UPA_T_remaining = UPA_T_remaining[UPA_T_remaining['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        \n",
    "        UPA_R_remaining = UPA_R.merge(intersection_df_1[[\"USER\",\"TCODE\"]], on=['USER', 'TCODE'], how='left', indicator=True)\n",
    "        UPA_R_remaining = UPA_R_remaining[UPA_R_remaining['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "        intersection_df_2 = pd.merge(UPA_I_remaining, UPA_R_remaining[['USER','TCODE']], on=['USER','TCODE'])\n",
    "        train_2, temp_2 = train_test_split(intersection_df_2, test_size=1-train_size, random_state=random_state)\n",
    "        val_2, test_2 = train_test_split(temp_2, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        UPA_I_train = pd.concat([train_1, train_2])\n",
    "        UPA_I_val = pd.concat([val_1, val_2])\n",
    "        UPA_I_test = pd.concat([test_1, test_2])\n",
    "        \n",
    "        UPA_T_train = train_1\n",
    "        UPA_T_val = val_1\n",
    "        UPA_T_test = test_1\n",
    "        \n",
    "        UPA_R_train = pd.concat([train_1, train_2])\n",
    "        UPA_R_val = pd.concat([val_1, val_2])\n",
    "        UPA_R_test = pd.concat([test_1, test_2])\n",
    "\n",
    "        def merge_with_target(df_train, df_val, df_test, df_target):\n",
    "            df_train_merged = df_train.merge(df_target[['USER','TCODE','Target']], on=['USER','TCODE'], how='left')\n",
    "            df_val_merged = df_val.merge(df_target[['USER','TCODE','Target']], on=['USER','TCODE'], how='left')\n",
    "            df_test_merged = df_test.merge(df_target[['USER','TCODE','Target']], on=['USER','TCODE'], how='left')\n",
    "            return df_train_merged, df_val_merged, df_test_merged\n",
    "        \n",
    "        UPA_I_train, UPA_I_val, UPA_I_test = merge_with_target(UPA_I_train, UPA_I_val, UPA_I_test, UPA_I_target)\n",
    "        UPA_T_train, UPA_T_val, UPA_T_test = merge_with_target(UPA_T_train, UPA_T_val, UPA_T_test, UPA_T_target)\n",
    "        UPA_R_train, UPA_R_val, UPA_R_test = merge_with_target(UPA_R_train, UPA_R_val, UPA_R_test, UPA_R_target)\n",
    "\n",
    "        X_UPA_I_train = UPA_I_train.drop(\"Target\", axis=1)\n",
    "        y_UPA_I_train = UPA_I_train[\"Target\"]\n",
    "        X_UPA_I_val = UPA_I_val.drop(\"Target\", axis=1)\n",
    "        y_UPA_I_val = UPA_I_val[\"Target\"]\n",
    "        X_UPA_I_test = UPA_I_test.drop(\"Target\", axis=1)\n",
    "        y_UPA_I_test = UPA_I_test[\"Target\"]\n",
    "\n",
    "        X_UPA_T_train = UPA_T_train.drop(\"Target\", axis=1)\n",
    "        y_UPA_T_train = UPA_T_train[\"Target\"]\n",
    "        X_UPA_T_val = UPA_T_val.drop(\"Target\", axis=1)\n",
    "        y_UPA_T_val = UPA_T_val[\"Target\"]\n",
    "        X_UPA_T_test = UPA_T_test.drop(\"Target\", axis=1)\n",
    "        y_UPA_T_test = UPA_T_test[\"Target\"]\n",
    "\n",
    "        X_UPA_R_train = UPA_R_train.drop(\"Target\", axis=1)\n",
    "        y_UPA_R_train = UPA_R_train[\"Target\"]\n",
    "        X_UPA_R_val = UPA_R_val.drop(\"Target\", axis=1)\n",
    "        y_UPA_R_val = UPA_R_val[\"Target\"]\n",
    "        X_UPA_R_test = UPA_R_test.drop(\"Target\", axis=1)\n",
    "        y_UPA_R_test = UPA_R_test[\"Target\"]\n",
    "\n",
    "        datasets = {\n",
    "            'UPA_I': {\n",
    "                'X_train': X_UPA_I_train, 'y_train': y_UPA_I_train,\n",
    "                'X_val': X_UPA_I_val, 'y_val': y_UPA_I_val,\n",
    "                'X_test': X_UPA_I_test, 'y_test': y_UPA_I_test},\n",
    "            'UPA_T': {\n",
    "                'X_train': X_UPA_T_train, 'y_train': y_UPA_T_train,\n",
    "                'X_val': X_UPA_T_val, 'y_val': y_UPA_T_val,\n",
    "                'X_test': X_UPA_T_test, 'y_test': y_UPA_T_test},\n",
    "            'UPA_R': {\n",
    "                'X_train': X_UPA_R_train, 'y_train': y_UPA_R_train,\n",
    "                'X_val': X_UPA_R_val, 'y_val': y_UPA_R_val,\n",
    "                'X_test': X_UPA_R_test, 'y_test': y_UPA_R_test}}\n",
    "\n",
    "        \n",
    "        params = {\n",
    "            'iterations': 1000,\n",
    "            'eval_metric': 'AUC',\n",
    "            'cat_features': cat_features_all_attributes,\n",
    "            'early_stopping_rounds': 100,\n",
    "            'verbose': 50,\n",
    "            'random_seed': random_state\n",
    "        }\n",
    "\n",
    "        for dataset_name, data in datasets.items():\n",
    "            print(f\"Processing {dataset_name}...\")\n",
    "            \n",
    "            X_train = data['X_train']\n",
    "            y_train = data['y_train']\n",
    "            X_val = data['X_val']\n",
    "            y_val = data['y_val']\n",
    "            X_test = data['X_test']\n",
    "            y_test = data['y_test']\n",
    "\n",
    "            num_ones = sum(y_test == 1)\n",
    "            num_zeros = sum(y_test == 0)\n",
    "            print(f\"Number of 1s in the test set: {num_ones}\")\n",
    "            print(f\"Number of 0s in the test set: {num_zeros}\")\n",
    "\n",
    "            start_time = time.time()\n",
    "            \n",
    "            cbc = CatBoostClassifier(**params)\n",
    "            cbc.fit(X_train, y_train,\n",
    "                    eval_set=(X_val, y_val),\n",
    "                    use_best_model=True,\n",
    "                    plot=False)\n",
    "    \n",
    "            y_test_pred_proba = cbc.predict_proba(X_test)[:, 1] \n",
    "            auc_score = roc_auc_score(y_test, y_test_pred_proba)\n",
    "            print(f'AUC Score Test-Data: {auc_score:.4f}')\n",
    "    \n",
    "            y_test_pred = cbc.predict(X_test)\n",
    "            f1_model = f1_score(y_test, y_test_pred)\n",
    "            print(f'F1 Score Test-Data (Model): {f1_model:.4f}')\n",
    "    \n",
    "            conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "            print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "    \n",
    "            tn, fp, fn, tp = conf_matrix.ravel()\n",
    "            feature_importance = dict(zip(X_train.columns, cbc.get_feature_importance()))\n",
    "    \n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "    \n",
    "            results.append({\n",
    "                'Dataset_Name': dataset_name,\n",
    "                'Run_Number': run + 1,\n",
    "                'Random_State': random_state,\n",
    "                'Number_of_Data_Points': len(X_train)+len(X_val)+len(X_test),\n",
    "                'Number_of_1s_in_Test_Set': num_ones,\n",
    "                'Number_of_0s_in_Test_Set': num_zeros,\n",
    "                'AUC_Score': auc_score,\n",
    "                'F1_Score': f1_model,\n",
    "                'TP': tp,\n",
    "                'FP': fp,\n",
    "                'TN': tn,\n",
    "                'FN': fn,\n",
    "                'Feature_Importance': feature_importance,\n",
    "                'Elapsed_Time': elapsed_time\n",
    "            })\n",
    "            \n",
    "            save_split_data(X_train, X_val, X_test, y_train, y_val, y_test, y_test_pred, y_test_pred_proba, tn, fp, fn, tp, dataset_name,run)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('Results_Randomsplit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56121a13-5374-4fba-91da-8d19239f22bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_runs = 10  \n",
    "train_size = 0.6\n",
    "test_size = 0.5\n",
    "\n",
    "run_model(num_runs, train_size, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4425d66d-5983-4436-b29b-69cad0c00edf",
   "metadata": {},
   "source": [
    "## Calculate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbdcded-e7ba-4148-86b6-6dca0fa11f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_delete_datasets(run):\n",
    "    UPA_I_file = f'UPA_I_run_{run+1}_Randomsplit.csv'\n",
    "    UPA_T_file = f'UPA_T_run_{run+1}_Randomsplit.csv'\n",
    "    UPA_R_file = f'UPA_R_run_{run+1}_Randomsplit.csv'\n",
    "    \n",
    "    UPA_I_df = pd.read_csv(UPA_I_file)\n",
    "    UPA_T_df = pd.read_csv(UPA_T_file)\n",
    "    UPA_R_df = pd.read_csv(UPA_R_file)\n",
    "\n",
    "    merged_df = UPA_I_df[['USER', 'TCODE', 'Split', 'True_Target', 'Predicted_Target']].merge(\n",
    "        UPA_T_df[['USER', 'TCODE', 'Split', 'True_Target', 'Predicted_Target']],\n",
    "        on=['USER', 'TCODE'],\n",
    "        how='left',\n",
    "        suffixes=('_UPA_I', '_UPA_T')\n",
    "    ).merge(\n",
    "        UPA_R_df[['USER', 'TCODE', 'Split', 'True_Target', 'Predicted_Target']],\n",
    "        on=['USER', 'TCODE'],\n",
    "        how='left',\n",
    "        suffixes=('', '_UPA_R')\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.rename(columns={\n",
    "        'Split_UPA_I': 'Split_UPA_I',\n",
    "        'True_Target_UPA_I': 'True_Target_UPA_I',\n",
    "        'Predicted_Target_UPA_I': 'Predicted_Target_UPA_I',\n",
    "        'Split_UPA_T': 'Split_UPA_T',\n",
    "        'True_Target_UPA_T': 'True_Target_UPA_T',\n",
    "        'Predicted_Target_UPA_T': 'Predicted_Target_UPA_T',\n",
    "        'Split': 'Split_UPA_R',\n",
    "        'True_Target': 'True_Target_UPA_R',\n",
    "        'Predicted_Target': 'Predicted_Target_UPA_R'\n",
    "    })\n",
    "\n",
    "    file_name = f'Combined_dataset_run_{run+1}_Randomsplit.csv'\n",
    "    merged_df.to_csv(file_name, index=False)\n",
    "    print(f'Combined dataset saved as {file_name}')\n",
    "\n",
    "    os.remove(UPA_I_file)\n",
    "    os.remove(UPA_T_file)\n",
    "    os.remove(UPA_R_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132feda1-79d9-452e-9874-4f97e73a9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(0,num_runs):\n",
    "    merge_and_delete_datasets(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e58f9-18cd-43af-b31e-ba2c25f3992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(1, num_runs + 1):\n",
    "    file_name = f\"Combined_dataset_run_{run}_Randomsplit.csv\"\n",
    "    globals()[f\"Combined_dataset_run_{run}_Randomsplit\"] = pd.read_csv(file_name, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7f412-9d2b-411b-979e-8737f1f6dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_info = [\n",
    "    {\"split_col\": \"Split_UPA_I\", \"true_col\": \"True_Target_UPA_I\", \"pred_col\": \"Predicted_Target_UPA_I\", \"name\": \"UPA_I\"},\n",
    "    {\"split_col\": \"Split_UPA_R\", \"true_col\": \"True_Target_UPA_R\", \"pred_col\": \"Predicted_Target_UPA_R\", \"name\": \"UPA_R\"},\n",
    "    {\"split_col\": \"Split_UPA_T\", \"true_col\": \"True_Target_UPA_T\", \"pred_col\": \"Predicted_Target_UPA_T\", \"name\": \"UPA_T\"},\n",
    "    {\"split_col\": \"Split_UPA_R\", \"true_col\": \"True_Target_UPA_R\", \"pred_col\": \"Predicted_Target_UPA_R\", \"name\": \"UPA_R_Assumption\", \"assumption\": True}\n",
    "]\n",
    "\n",
    "num_runs = 10\n",
    "f1_scores_over_runs = {dataset['name']: {\"f1_pos\": [], \"f1_neg\": [], \"f1_macro\": [], \"f1_weighted\": [], \"baseline_f1\": []} for dataset in datasets_info}\n",
    "\n",
    "for run in range(1, num_runs + 1):\n",
    "    combined_dataset_name = f\"Combined_dataset_run_{run}_Randomsplit\"\n",
    "    combined_dataset = globals()[combined_dataset_name]\n",
    "    \n",
    "    print(f\"\\n===== Ergebnisse für Run {run} =====\")\n",
    "    \n",
    "    for dataset in datasets_info:\n",
    "        results = combined_dataset[[dataset['true_col'], dataset['pred_col']]].loc[combined_dataset[dataset['split_col']] == \"Test\"]\n",
    "        \n",
    "        if dataset.get(\"assumption\"):\n",
    "            results[dataset['true_col']] = results[dataset['true_col']].fillna(0.0)\n",
    "            results[dataset['pred_col']] = results[dataset['pred_col']].fillna(0.0)\n",
    "\n",
    "        class_distribution = results[dataset['true_col']].value_counts(normalize=True)\n",
    "        p_0 = class_distribution.get(0, 0) \n",
    "        p_1 = class_distribution.get(1, 0) \n",
    "        \n",
    "        baseline_predictions = np.random.choice([0, 1], size=len(results), p=[p_0, p_1])\n",
    "        baseline_f1 = f1_score(results[dataset['true_col']], baseline_predictions)\n",
    "\n",
    "        print(f\"Results for {dataset['name']} in Run {run}:\")\n",
    "        print(f\"Baseline F1 Score für {dataset['name']} in Run {run}: {baseline_f1:.4f}\")\n",
    "        \n",
    "        f1_pos = f1_score(results[dataset['true_col']], results[dataset['pred_col']], pos_label=1)\n",
    "        f1_neg = f1_score(results[dataset['true_col']], results[dataset['pred_col']], pos_label=0)\n",
    "        f1_macro = f1_score(results[dataset['true_col']], results[dataset['pred_col']], average=\"macro\")\n",
    "        f1_weighted = f1_score(results[dataset['true_col']], results[dataset['pred_col']], average=\"weighted\")\n",
    "        \n",
    "        cm = confusion_matrix(results[dataset['true_col']], results[dataset['pred_col']])\n",
    "        \n",
    "        print(\"Pos F1: \" + str(f1_pos))\n",
    "        print(\"Neg F1: \" + str(f1_neg))\n",
    "        print(\"Macro F1: \" + str(f1_macro))\n",
    "        print(\"Weighted F1: \" + str(f1_weighted))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "        print(\"\\n\")\n",
    "\n",
    "        f1_scores_over_runs[dataset['name']]['baseline_f1'].append(baseline_f1)\n",
    "        f1_scores_over_runs[dataset['name']]['f1_pos'].append(f1_pos)\n",
    "        f1_scores_over_runs[dataset['name']]['f1_neg'].append(f1_neg)\n",
    "        f1_scores_over_runs[dataset['name']]['f1_macro'].append(f1_macro)\n",
    "        f1_scores_over_runs[dataset['name']]['f1_weighted'].append(f1_weighted)\n",
    "        f1_scores_over_runs[dataset['name']]['baseline_f1'].append(baseline_f1)\n",
    "\n",
    "print(\"\\n===== Avg and Std per Run =====\")\n",
    "for dataset in datasets_info:\n",
    "    name = dataset['name']\n",
    "    \n",
    "    avg_baseline_f1 = np.mean(f1_scores_over_runs[name]['baseline_f1'])\n",
    "    avg_f1_pos = np.mean(f1_scores_over_runs[name]['f1_pos'])\n",
    "    avg_f1_neg = np.mean(f1_scores_over_runs[name]['f1_neg'])\n",
    "    avg_f1_macro = np.mean(f1_scores_over_runs[name]['f1_macro'])\n",
    "    avg_f1_weighted = np.mean(f1_scores_over_runs[name]['f1_weighted'])\n",
    "    \n",
    "    std_baseline_f1 = np.std(f1_scores_over_runs[name]['baseline_f1'])\n",
    "    std_f1_pos = np.std(f1_scores_over_runs[name]['f1_pos'])\n",
    "    std_f1_neg = np.std(f1_scores_over_runs[name]['f1_neg'])\n",
    "    std_f1_macro = np.std(f1_scores_over_runs[name]['f1_macro'])\n",
    "    std_f1_weighted = np.std(f1_scores_over_runs[name]['f1_weighted'])\n",
    "    \n",
    "    print(f\"\\nAvg and Std for {name}:\")\n",
    "    print(f\"Avg Baseline F1: {avg_baseline_f1:.4f} (Std: {std_baseline_f1:.4f})\")\n",
    "    print(f\"Avg Pos F1: {avg_f1_pos:.4f} (Std: {std_f1_pos:.4f})\")\n",
    "    print(f\"Avg Neg F1: {avg_f1_neg:.4f} (Std: {std_f1_neg:.4f})\")\n",
    "    print(f\"Avg Macro F1: {avg_f1_macro:.4f} (Std: {std_f1_macro:.4f})\")\n",
    "    print(f\"Avg Weighted F1: {avg_f1_weighted:.4f} (Std: {std_f1_weighted:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
